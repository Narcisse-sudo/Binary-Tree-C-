
# ğŸŒ³ Projet : Arbres de dÃ©cision et prÃ©diction par *bagging* dâ€™arbres en C++

Ce projet a pour objectif de concevoir et dâ€™implÃ©menter en C++ un modÃ¨le dâ€™arbre binaire de
dÃ©cision capable de traiter des donnÃ©es quantitatives et qualitatives, tant en classification quâ€™en
rÃ©gression. Lâ€™approche repose sur la construction rÃ©cursive de lâ€™arbre en utilisant des critÃ¨res
dâ€™homogÃ©nÃ©itÃ© tels que la variance pour les variables continues et lâ€™indice de Gini pour les
variables catÃ©gorielles.

Lâ€™architecture du code repose sur des classes hiÃ©rarchisÃ©es **(Noeud, Arbre, Data, Attri-
but, DataIndividu)** assurant une modularitÃ© et une clartÃ© dans la construction des arbres.
Le rapport dÃ©taille Ã©galement lâ€™ajout dâ€™une fonctionnalitÃ© de visualisation automatique via la
gÃ©nÃ©ration de fichiers .dot compatibles avec Graphviz, facilitant lâ€™interprÃ¨tation graphique
des arbres gÃ©nÃ©rÃ©s.

Une extension du projet a Ã©tÃ© rÃ©alisÃ©e Ã  travers lâ€™intÃ©gration de lâ€™algorithme **Bagging** (Boots-
trap Aggregating), permettant dâ€™amÃ©liorer la stabilitÃ© et la prÃ©cision des prÃ©dictions par la
combinaison de plusieurs arbres construits sur des Ã©chantillons bootstrapÃ©s.


---

## ğŸ“‚ Structure du Code

### ğŸ§© Classes Principales

#### 1. `Arbre`
- **RÃ´le** : CrÃ©e et entraÃ®ne l'arbre de dÃ©cision.
- **MÃ©thodes principales** :
  - `Gini` : Calcule lâ€™hÃ©tÃ©rogÃ©nÃ©itÃ© pour une variable qualitative.
  - `gainGini` : Mesure le gain dâ€™information selon lâ€™indice de Gini.
  - `Variance` : Calcule lâ€™hÃ©tÃ©rogÃ©nÃ©itÃ© pour une variable quantitative.
  - `gainVariance` : Mesure le gain dâ€™information selon la variance.
  - `creerNoeud`, `diviserNoeud` : Construction rÃ©cursive des nÅ“uds.
  - `critereArret` : Conditions dâ€™arrÃªt de croissance de lâ€™arbre.
  - `exporterGraphviz` : GÃ©nÃ¨re un `.dot` pour visualisation.
  - `calculerPredictionsFeuilles` : Affecte une prÃ©diction Ã  chaque feuille.
  - **Public** :
    - `predire` : PrÃ©dit la classe dâ€™un individu.
    - `evaluerTestSet` : Ã‰value lâ€™arbre (renvoie prÃ©dictions + score).
    - `creer_Arbre` : Initialise lâ€™arbre.

#### 2. `BaggingArbre`
- **RÃ´le** : EntraÃ®ne plusieurs arbres sur des sous-Ã©chantillons bootstrapÃ©s.
- **MÃ©thodes** :
  - `entrainer` : GÃ©nÃ©re plusieurs jeux bootstrap et entraÃ®ne un arbre sur chacun.

#### 3. `Noeud` *(classe de base)*
- **RÃ´le** : ReprÃ©sente tout type de nÅ“ud.
- Ã‰tendue par :
  - `NoeudFeuille`
  - `NoeudQuantitatif`
  - `NoeudQualitatif`

#### 4. `NoeudFeuille`
- **RÃ´le** : NÅ“ud terminal avec une prÃ©diction.
- **Attributs** : `prediction`, `vectIndiceInd`.

#### 5. `NoeudQuantitatif`
- **RÃ´le** : NÅ“ud avec une variable quantitative.
- **Attributs** : `seuilOpti`.

#### 6. `NoeudQualitatif`
- **RÃ´le** : NÅ“ud avec variable qualitative.
- **Attributs** : `meilleurGroupe`.

#### 7. `Data`
- **RÃ´le** : Stocke les donnÃ©es dâ€™entrÃ©e.
- **Contenu** :
  - `V`, `NomVar`, `TypeVar`, `cat`.
  - `Train_Test_Split` : SÃ©paration entraÃ®nement/test.

#### 8. `DataIndividu`
- **RÃ´le** : ReprÃ©sente un individu avec ses attributs.

---

## ğŸ›‘ MÃ©thodes importantes

###  CritÃ¨res de division
- **Gini** : UtilisÃ© pour les variables qualitatives.
- **Variance** : UtilisÃ©e pour les variables quantitatives.
- Le **gain** (d'information) permet de choisir la variable et la coupure optimale.

###  CritÃ¨res d'arrÃªt
- Nombre minimum dâ€™individus dans un nÅ“ud (ex : 10)
- PuretÃ© maximale du nÅ“ud

###  PrÃ©diction
- Lâ€™individu est classÃ© en suivant les branches de lâ€™arbre jusquâ€™Ã  une feuille.

---

## ğŸ–¼ï¸ Visualisation

Lâ€™arbre est exportÃ© en `.dot` :
```bash
dot -Tpng arbre.dot -o arbre.png
